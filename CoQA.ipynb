{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer.Config import Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Transformer.Trainer.Tokenizer import TokenizerPlus\n",
    "from Transformer.Trainer.Trainer import Trainer\n",
    "from Transformer.Trainer.decoding import greedy_decoding\n",
    "from Transformer.Config import Config\n",
    "from Transformer.Model import Transformer\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "raw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'New Action', 'fr': 'Nouvelle action'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][3][\"translation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/pytorchVenv/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/pytorchVenv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
    "fr_sentence = split_datasets[\"train\"][1][\"translation\"][\"fr\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(fr_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Par', '▁dé', 'f', 'aut', ',', '▁dé', 've', 'lop', 'per', '▁les', '▁fil', 's', '▁de', '▁discussion', '</s>']\n",
      "['▁Par', '▁défaut', ',', '▁développer', '▁les', '▁fils', '▁de', '▁discussion', '</s>']\n"
     ]
    }
   ],
   "source": [
    "wrong_targets = tokenizer(fr_sentence)\n",
    "print(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(targets[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # 타겟을 위한 토크나이저 셋업\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "validation_dataset = tokenized_datasets[\"validation\"]\n",
    "\n",
    "X_train = train_dataset[\"input_ids\"]\n",
    "y_train = train_dataset[\"labels\"]\n",
    "\n",
    "X_val = validation_dataset[\"input_ids\"]\n",
    "y_val = validation_dataset[\"labels\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([189155, 128]) torch.Size([189155, 128])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "X_train = [torch.tensor(seq) for seq in X_train]\n",
    "y_train = [torch.tensor(seq) for seq in y_train]\n",
    "X_train= pad_sequence([seq.flip(0) for seq in X_train], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "y_train= pad_sequence([seq.flip(0) for seq in y_train], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21018, 128]) torch.Size([21018, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_val = [torch.tensor(seq) for seq in X_val]\n",
    "y_val = [torch.tensor(seq) for seq in y_val]\n",
    "X_val= pad_sequence([seq.flip(0) for seq in X_val], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "y_val= pad_sequence([seq.flip(0) for seq in y_val], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "print(X_val.shape,y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 59515, 'n_dec_vocab': 59515, 'n_enc_seq': 128, 'n_dec_seq': 128, 'n_layer': 4, 'd_hidn': 128, 'i_pad': 0, 'd_ff': 256, 'n_head': 4, 'd_head': 128, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
     ]
    }
   ],
   "source": [
    "n=128\n",
    "config=Config(len(tokenizer.get_vocab())+1)\n",
    "config.n_enc_seq=n\n",
    "config.n_dec_seq=n\n",
    "config.d_hidn=n\n",
    "config.d_ff=n*2\n",
    "config.d_head=n\n",
    "config.n_layer=4\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([189155, 128])\n",
      "<class 'torch.Tensor'> torch.Size([189155, 128])\n",
      "<class 'torch.Tensor'> torch.Size([21018, 128])\n",
      "<class 'torch.Tensor'> torch.Size([21018, 128])\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> ▁Calibration is▁about to check the▁value▁range your▁device▁delivers.▁Please▁move▁axis %1 %2 on your▁device to the maximum position. Press▁any▁button on the▁device or▁click on the'Next 'button to continue with the▁next▁step.\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Le calibrage va vérifier la plage de valeurs que votre matériel produit. Veuillez déplacer l'axe %1 %2 de votre périphérique à la position maximale. Appuyez sur n'importe quel bouton du périphérique ou sur le bouton « & #160; Suivant & #160; » pour la prochaine étape.\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),X_train.shape)\n",
    "print(type(y_train),y_train.shape)\n",
    "print(type(X_val),X_val.shape)\n",
    "print(type(y_val),y_val.shape)\n",
    "print(tokenizer.convert_tokens_to_string([i for i in tokenizer.convert_ids_to_tokens(X_train[0]) if i != tokenizer.eos_token]))\n",
    "print(tokenizer.convert_tokens_to_string([i for i in tokenizer.convert_ids_to_tokens(y_train[0]) if i != tokenizer.eos_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch   1/4)   Batch:1/2956   Cost:11.479726"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'num' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m      6\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, loss_fn, optimizer,dec_fnc\u001b[39m=\u001b[39mgreedy_decoding,tokenizer\u001b[39m=\u001b[39mtokenizer)\n\u001b[0;32m----> 7\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(src\u001b[39m=\u001b[39;49mX_train, tgt\u001b[39m=\u001b[39;49my_train, \n\u001b[1;32m      8\u001b[0m               val_src\u001b[39m=\u001b[39;49mX_val[:\u001b[39m20\u001b[39;49m], val_tgt\u001b[39m=\u001b[39;49m y_val[:\u001b[39m20\u001b[39;49m], max_epoch\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/HUMANE lab/project/transformer_impl/Transformer/Trainer/Trainer.py:60\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, src, tgt, val_src, val_tgt, max_epoch, batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(running_loss \u001b[39m/\u001b[39m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m3\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mappend(running_loss)\n\u001b[0;32m---> 60\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(val_src, val_tgt[:,\u001b[39m1\u001b[39;49m:])\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m        Running_Loss: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m(running_loss), \u001b[39m\"\u001b[39m\u001b[39mVAL_ACC: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39macc)\n",
      "File \u001b[0;32m~/Desktop/HUMANE lab/project/transformer_impl/Transformer/Trainer/Trainer.py:64\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, src, y)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, src, y):\n\u001b[0;32m---> 64\u001b[0m     pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdec_fnc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,src, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer,num))\n\u001b[1;32m     65\u001b[0m     num\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m     66\u001b[0m     y_text \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y[:,:num\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'num' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens\n",
    "model = Transformer(config)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "trainer = Trainer(model, loss_fn, optimizer,dec_fnc=greedy_decoding,tokenizer=tokenizer)\n",
    "trainer.train(src=X_train, tgt=y_train, \n",
    "              val_src=X_val[:20], val_tgt= y_val[:20], max_epoch=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'complete_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
