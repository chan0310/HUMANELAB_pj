{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transformer.Config import Config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Transformer.Trainer.Tokenizer import TokenizerPlus\n",
    "from Transformer.Trainer.Trainer import Trainer\n",
    "from Transformer.Trainer.decoding import greedy_decoding\n",
    "from Transformer.Config import Config\n",
    "from Transformer.Model import Transformer\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/ichan-u/.cache/huggingface/modules/datasets_modules/datasets/kde4/243129fb2398d5b0b4f7f6831ab27ad84774b7ce374cf10f60f6e1ff331648ac (last modified on Wed Aug 16 20:12:54 2023) since it couldn't be found locally at kde4., or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "raw_datasets = load_dataset(\"kde4\", lang1=\"en\", lang2=\"fr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'New Action', 'fr': 'Nouvelle action'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][3][\"translation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentence = split_datasets[\"train\"][1][\"translation\"][\"en\"]\n",
    "fr_sentence = split_datasets[\"train\"][1][\"translation\"][\"fr\"]\n",
    "\n",
    "inputs = tokenizer(en_sentence)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(fr_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Par', '▁dé', 'f', 'aut', ',', '▁dé', 've', 'lop', 'per', '▁les', '▁fil', 's', '▁de', '▁discussion', '</s>']\n",
      "['▁Par', '▁défaut', ',', '▁développer', '▁les', '▁fils', '▁de', '▁discussion', '</s>']\n"
     ]
    }
   ],
   "source": [
    "wrong_targets = tokenizer(fr_sentence)\n",
    "print(tokenizer.convert_ids_to_tokens(wrong_targets[\"input_ids\"]))\n",
    "print(tokenizer.convert_ids_to_tokens(targets[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # 타겟을 위한 토크나이저 셋업\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "validation_dataset = tokenized_datasets[\"validation\"]\n",
    "\n",
    "X_train = train_dataset[\"input_ids\"]\n",
    "y_train = train_dataset[\"labels\"]\n",
    "\n",
    "X_val = validation_dataset[\"input_ids\"]\n",
    "y_val = validation_dataset[\"labels\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([189155, 128]) torch.Size([189155, 128])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "X_train = [torch.tensor(seq) for seq in X_train]\n",
    "y_train = [torch.tensor(seq) for seq in y_train]\n",
    "X_train= pad_sequence([seq.flip(0) for seq in X_train], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "y_train= pad_sequence([seq.flip(0) for seq in y_train], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21018, 128]) torch.Size([21018, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_val = [torch.tensor(seq) for seq in X_val]\n",
    "y_val = [torch.tensor(seq) for seq in y_val]\n",
    "X_val= pad_sequence([seq.flip(0) for seq in X_val], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "y_val= pad_sequence([seq.flip(0) for seq in y_val], batch_first=True, padding_value=tokenizer.pad_token_id).flip(1)\n",
    "print(X_val.shape,y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59514"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_enc_vocab': 59515, 'n_dec_vocab': 59515, 'n_enc_seq': 128, 'n_dec_seq': 128, 'n_layer': 4, 'd_hidn': 128, 'i_pad': 0, 'd_ff': 256, 'n_head': 4, 'd_head': 128, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
     ]
    }
   ],
   "source": [
    "n=128\n",
    "config=Config(len(tokenizer.get_vocab())+1)\n",
    "config.n_enc_seq=n\n",
    "config.n_dec_seq=n\n",
    "config.d_hidn=n\n",
    "config.d_ff=n*2\n",
    "config.d_head=n\n",
    "config.n_layer=4\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([189155, 128])\n",
      "<class 'torch.Tensor'> torch.Size([189155, 128])\n",
      "<class 'torch.Tensor'> torch.Size([21018, 128])\n",
      "<class 'torch.Tensor'> torch.Size([21018, 128])\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> ▁Calibration is▁about to check the▁value▁range your▁device▁delivers.▁Please▁move▁axis %1 %2 on your▁device to the maximum position. Press▁any▁button on the▁device or▁click on the'Next 'button to continue with the▁next▁step.\n",
      "<pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> Le calibrage va vérifier la plage de valeurs que votre matériel produit. Veuillez déplacer l'axe %1 %2 de votre périphérique à la position maximale. Appuyez sur n'importe quel bouton du périphérique ou sur le bouton « & #160; Suivant & #160; » pour la prochaine étape.\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),X_train.shape)\n",
    "print(type(y_train),y_train.shape)\n",
    "print(type(X_val),X_val.shape)\n",
    "print(type(y_val),y_val.shape)\n",
    "print(tokenizer.convert_tokens_to_string([i for i in tokenizer.convert_ids_to_tokens(X_train[0]) if i != tokenizer.eos_token]))\n",
    "print(tokenizer.convert_tokens_to_string([i for i in tokenizer.convert_ids_to_tokens(y_train[0]) if i != tokenizer.eos_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch   1/4)   Batch:1/2956   Cost:11.651671"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m      6\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, loss_fn, optimizer,dec_fnc\u001b[39m=\u001b[39mgreedy_decoding,tokenizer\u001b[39m=\u001b[39mtokenizer)\n\u001b[0;32m----> 7\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(src\u001b[39m=\u001b[39;49mX_train, tgt\u001b[39m=\u001b[39;49my_train, \n\u001b[1;32m      8\u001b[0m               val_src\u001b[39m=\u001b[39;49mX_val[:\u001b[39m200\u001b[39;49m], val_tgt\u001b[39m=\u001b[39;49m y_val[:\u001b[39m200\u001b[39;49m], max_epoch\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/HUMANE lab/project/transformer_impl/Transformer/Trainer/Trainer.py:60\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, src, tgt, val_src, val_tgt, max_epoch, batch_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(running_loss \u001b[39m/\u001b[39m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m3\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mappend(running_loss)\n\u001b[0;32m---> 60\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(val_src, val_tgt[:,\u001b[39m1\u001b[39;49m:])\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m        Running_Loss: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m(running_loss), \u001b[39m\"\u001b[39m\u001b[39mVAL_ACC: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39macc)\n",
      "File \u001b[0;32m~/Desktop/HUMANE lab/project/transformer_impl/Transformer/Trainer/Trainer.py:65\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, src, y)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m, src, y):\n\u001b[1;32m     64\u001b[0m     num\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m---> 65\u001b[0m     pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdec_fnc(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,src, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer,num))\n\u001b[1;32m     66\u001b[0m     y_text \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y[:,:num\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     67\u001b[0m     \u001b[39mprint\u001b[39m(pred\u001b[39m.\u001b[39mshape,y_text\u001b[39m.\u001b[39mshape,pred\u001b[39m.\u001b[39msize)\n",
      "File \u001b[0;32m~/Desktop/HUMANE lab/project/transformer_impl/Transformer/Trainer/Trainer.py:18\u001b[0m, in \u001b[0;36mgreedy_decoding\u001b[0;34m(trm, src, detokenizer, num, start_token)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     17\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num):\n\u001b[0;32m---> 18\u001b[0m         y_pred,a,b,c \u001b[39m=\u001b[39m trm(src,preds)\n\u001b[1;32m     19\u001b[0m         t_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(y_pred[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m         preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([preds, t_pred], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)            \n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pytorchVenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/HUMANE lab/project/transformer_impl/Transformer/Model.py:19\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, enc_inputs, dec_inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m dec_outputs, dec_self_attn_probs, dec_enc_attn_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(dec_inputs, enc_inputs, enc_outputs)\n\u001b[1;32m     18\u001b[0m \u001b[39m# (batchs, n_dec_seq, n_dec_vocab)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m dec_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprojection(dec_outputs)\n\u001b[1;32m     20\u001b[0m \u001b[39m# (batchs, n_dec_seq, n_dec_vocab), [(batchs, n_head, n_enc_seq, n_enc_seq)], [(batchs, n_head, n_dec_seq, n_dec_seq)], [(batchs, n_head, n_dec_seq, n_enc_seq)]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pytorchVenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pytorchVenv/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens\n",
    "model = Transformer(config)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "trainer = Trainer(model, loss_fn, optimizer,dec_fnc=greedy_decoding,tokenizer=tokenizer)\n",
    "trainer.train(src=X_train, tgt=y_train, \n",
    "              val_src=X_val[:200], val_tgt= y_val[:200], max_epoch=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'complete_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
