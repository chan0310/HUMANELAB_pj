{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n",
      "Set\n"
     ]
    }
   ],
   "source": [
    "from Transformer.Config import Config\n",
    "from Transformer.Model import Transformer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from Seq2SeqModel.Seq2SeqModel import Seq2SeqModel\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# CSV 파일에서 데이터 불러오기\n",
    "df_train = pd.read_csv(\"Datatset/train.csv\")\n",
    "df_val = pd.read_csv(\"Datatset/val.csv\")\n",
    "tokenizer= AutoTokenizer.from_pretrained(\"Datatset/tokenizer\")\n",
    "\n",
    "def str_to_list(input_string):\n",
    "    cleaned_string = input_string.strip(\"[]\").replace(\" \", \"\")\n",
    "\n",
    "    number_strings = cleaned_string.split(\",\")\n",
    "    number_list = [int(num) for num in number_strings]\n",
    "    return number_list\n",
    "\n",
    "# 데이터 추출\n",
    "X_train = df_train[\"X_train\"].values.tolist()\n",
    "X_train=[str_to_list(i) for i in X_train]\n",
    "y_train = df_train[\"y_train\"].values.tolist()\n",
    "y_train=[str_to_list(i) for i in y_train]\n",
    "\n",
    "\n",
    "X_val = df_val[\"X_val\"].values.tolist()\n",
    "X_val=[str_to_list(i) for i in X_val]\n",
    "y_val = df_val[\"y_val\"].values.tolist()\n",
    "y_val=[str_to_list(i) for i in y_val]\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "print(f'Using {device}')\n",
    "\n",
    "tokenizer= AutoTokenizer.from_pretrained(\"Datatset/tokenizer\")\n",
    "config=Config(3)\n",
    "model=Transformer(config)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-11)\n",
    "batchsize=64\n",
    "print(\"Set\")\n",
    "module=Seq2SeqModel( model,tokenizer,optimizer,loss_fn,\n",
    "                    X_train,y_train,X_val,y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos> ▁Calibration is▁about to check the▁value▁range your▁device▁delivers.▁Please▁move▁axis %1 %2 on your▁device to the maximum position. Press▁any▁button on the▁device or▁click on the'Next 'button to continue with the▁next▁step.\n",
      "<bos> Le calibrage va vérifier la plage de valeurs que votre matériel produit. Veuillez déplacer l'axe %1 %2 de votre périphérique à la position maximale. Appuyez sur n'importe quel bouton du périphérique ou sur le bouton « & #160; Suivant & #160; » pour la prochaine étape.</s>\n",
      "[59514, 34378, 226, 5783, 32, 200, 12, 3647, 4, 1223, 1628, 117, 4923, 23608, 3, 1789, 2942, 20059, 301, 548, 301, 331, 30, 117, 4923, 12, 4, 1528, 668, 3, 5734, 212, 9319, 30, 4, 4923, 57, 5487, 30, 4, 6, 32712, 25, 7243, 1160, 12, 621, 42, 4, 1156, 3009, 3, 0]\n",
      "[59514, 60, 7418, 5244, 8234, 740, 4993, 8, 6471, 5, 2218, 29, 193, 2220, 742, 3, 4366, 14237, 14, 6, 16600, 301, 548, 301, 331, 5, 193, 24275, 17, 8, 668, 6142, 3, 33640, 36, 81, 6, 5411, 2709, 9376, 22, 24275, 59, 36, 19, 9376, 153, 402, 29033, 13774, 402, 29033, 416, 27, 8, 4034, 4888, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(X_train[0])))\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(y_train[0])))\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_padd:  128\n",
      "seq_padd:  128\n",
      "<bos> ▁Calibration is▁about to check the▁value▁range your▁device▁delivers.▁Please▁move▁axis %1 %2 on your▁device to the maximum position. Press▁any▁button on the▁device or▁click on the'Next 'button to continue with the▁next▁step.\n",
      "tensor([17833,  2332,  2332,  2332, 17154, 17154, 51385, 51385, 51385, 17154,\n",
      "        17154, 17154, 51385, 51385, 25337, 17154, 17154, 40291, 40291, 21398,\n",
      "        33386,  4875, 51385, 51385, 51385, 51385, 30212, 30212, 30212, 30212,\n",
      "        30212, 51385, 51385, 51385, 51385, 51385, 51385, 51385, 51385, 51385,\n",
      "        50510, 50510, 50510, 51385, 51385, 51385, 51671, 50983, 21398, 21398,\n",
      "        21398, 50510, 49137, 49137, 50983, 51385, 51385, 51385, 25337, 25337,\n",
      "        25337, 51385, 51385,   860,   860,   860, 47255, 47255, 51671, 51671,\n",
      "        51671, 51671, 51385, 51385, 51385, 51385, 51385, 51385, 40269, 40269,\n",
      "        51385, 51385, 51385, 45835, 45835, 47255, 47255, 47255, 51385, 51385,\n",
      "        49137,   924, 47255, 47255, 51385, 51385, 44622, 12016, 12016, 12016,\n",
      "          860,   860,   860,   860,   860,   860, 47255, 47255, 47255, 29964,\n",
      "        45921, 51671, 51671, 51671, 47255, 47255, 47255, 47255, 47255, 47255,\n",
      "        47255, 47255, 47255, 47255, 47255, 47255, 21398, 21398]) torch.Size([128])\n",
      "drôle torture torture tortureACIAACIA扣扣扣ACIAACIAACIA扣扣▁RacismACIAACIAinsurrectioninsurrection▁Exhibitaoui respective扣扣扣扣 pittoresque pittoresque pittoresque pittoresque pittoresque扣扣扣扣扣扣扣扣扣项项项扣扣扣흔적票▁Exhibit▁Exhibit▁Exhibit项∧∧票扣扣扣▁Racism▁Racism▁Racism扣扣▁political▁political▁political▁organisers▁organisers흔적흔적흔적흔적扣扣扣扣扣扣 correspondait correspondait扣扣扣traffickingtrafficking▁organisers▁organisers▁organisers扣扣∧ beaucoup▁organisers▁organisers扣扣▁devastated douane douane douane▁political▁political▁political▁political▁political▁political▁organisers▁organisers▁organisers▁0.8▁Episode흔적흔적흔적▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁organisers▁Exhibit▁Exhibit\n"
     ]
    }
   ],
   "source": [
    "module.model.eval()\n",
    "i_e=torch.tensor(X_train[0][:-1])\n",
    "out=torch.tensor(module.seq_to_seq_process(i_e))\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(i_e)))\n",
    "print(out,out.shape)\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
